{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "sys.path.insert(0,'/')\n",
    "concordance = []\n",
    "brier = []\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import TRiskSurv.pytorch_pretrained_bert as Bert\n",
    "\n",
    "from TRiskSurv. pytorch_pretrained_bert import optimizer\n",
    "import sklearn.metrics as skm\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from TRiskSurv.ModelPkg.utils import *\n",
    "\n",
    "sys.path.insert(0, '/ModelPkg/')\n",
    "from TRiskSurv.ModelPkg.BEHRTsurv import *\n",
    "from TRiskSurv.ModelPkg.Data_Deterministic import *\n",
    "from TRiskSurv.ModelPkg.utils import *\n",
    "import matplotlib as plt\n",
    "\n",
    "from torch import optim as toptimizer\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "\n",
    "from TRiskSurv.ModelPkg.TriSched import *\n",
    "\n",
    "from TRiskSurv.ModelPkg.CPHloss import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainloop(e, binaryFlag=False):\n",
    "    if binaryFlag:\n",
    "        print('binary on...')\n",
    "\n",
    "    dataset_train = Binary_DeepSurvDataset(BertVocab['token2idx'], train, global_params['max_len_seq'], max_age=110, year=True, age_symbol=None, min_visit=5)\n",
    "\n",
    "\n",
    "    dl_train = DataLoader(dataset_train, global_params['batch_size'], shuffle=True)\n",
    "\n",
    "\n",
    "    \n",
    "    model.train()\n",
    "    model.binary=binaryFlag\n",
    "    tr_loss = 0\n",
    "    temp_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    cnt = 0\n",
    "\n",
    "    for step, batch in enumerate(dl_train):\n",
    "        cnt += 1\n",
    "\n",
    "        \n",
    "        age_ids, input_ids, posi_ids, segment_ids, attMask, time2event, label, labelfloat = batch\n",
    "\n",
    "        age_ids = age_ids.to(global_params['device'])\n",
    "        input_ids = input_ids.to(global_params['device'])\n",
    "        posi_ids = posi_ids.to(global_params['device'])\n",
    "        segment_ids = segment_ids.to(global_params['device'])\n",
    "        attMask = attMask.to(global_params['device'])\n",
    "        time2event = time2event.to(global_params['device'])\n",
    "        label = label.to(global_params['device'])\n",
    "        labelfloat = labelfloat.to(global_params['device'])\n",
    "\n",
    "        logits , loss= model(input_ids, age_ids, segment_ids, posi_ids, attMask, label, labelfloat, time2event)\n",
    "\n",
    "        if global_params['gradient_accumulation_steps'] > 1:\n",
    "            loss = loss / global_params['gradient_accumulation_steps']\n",
    "        loss.backward()\n",
    "\n",
    "        temp_loss += loss.item()\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        if step % 100 == 0:\n",
    "            if BINFLAG:\n",
    "                prec, a, b = precision(logits, labelfloat)\n",
    "            else:\n",
    "                prec = -1\n",
    "            print(\"epoch: {}\\t| Cnt: {}\\t| Loss: {}\\t| precision: {}\".format(e, cnt, temp_loss / 100, prec))\n",
    "            temp_loss = 0\n",
    "\n",
    "        if (step + 1) % global_params['gradient_accumulation_steps'] == 0:\n",
    "            optim.step()\n",
    "        optim.zero_grad()\n",
    "    del dl_train\n",
    "    return e\n",
    "\n",
    "\n",
    "\n",
    "def evaluationloop(binaryFlag=False):\n",
    "    if binaryFlag:\n",
    "        print('binary on...')\n",
    "\n",
    "\n",
    "    dataset_test = Binary_DeepSurvDataset(BertVocab['token2idx'], test, global_params['max_len_seq'], max_age=110, year=True, age_symbol=None, min_visit=5)\n",
    "\n",
    "    dl_test = DataLoader(dataset_test, global_params['batch_size'], shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "    y = []\n",
    "    y_label = []\n",
    "    loss_temp = 0\n",
    "    model.binary=binaryFlag\n",
    "    y_time = []\n",
    "    \n",
    "    for step, batch in enumerate(dl_test):\n",
    "        model.eval()\n",
    "\n",
    "        \n",
    "        age_ids, input_ids, posi_ids, segment_ids, attMask, time2event, label, labelfloat = batch\n",
    "\n",
    "        age_ids = age_ids.to(global_params['device'])\n",
    "        input_ids = input_ids.to(global_params['device'])\n",
    "        posi_ids = posi_ids.to(global_params['device'])\n",
    "        segment_ids = segment_ids.to(global_params['device'])\n",
    "        attMask = attMask.to(global_params['device'])\n",
    "        time2event = time2event.to(global_params['device'])\n",
    "        label = label.to(global_params['device'])\n",
    "        labelfloat = labelfloat.to(global_params['device'])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits , loss= model(input_ids, age_ids, segment_ids, posi_ids, attMask, label,labelfloat, time2event)\n",
    "\n",
    "        logits = logits.cpu()\n",
    "        labelfloat = labelfloat.cpu()\n",
    "        time2event = time2event.cpu()\n",
    "        if step % 50 == 0:\n",
    "            print(step)\n",
    "        y_label.append(labelfloat)\n",
    "        y.append(logits)\n",
    "        y_time.append(time2event)\n",
    "        loss_temp = loss_temp+loss.item()\n",
    "    y_label = torch.cat(y_label, dim=0)\n",
    "    y = torch.cat(y, dim=0)\n",
    "    y_time = torch.cat(y_time, dim=0)\n",
    "    \n",
    "    if BINFLAG:\n",
    "        tempprc, output, label = precision_test(y, y_label)\n",
    "\n",
    "        tempauroc, output, label = roc_auc(y, y_label)\n",
    "\n",
    "    else:\n",
    "        tempprc, output, label = precision_test(y, y_label)\n",
    "\n",
    "        tempauroc = cindex(y, y_label, y_time)\n",
    "    \n",
    "        \n",
    "    \n",
    "    return tempprc, tempauroc, loss_temp\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validationloop(binaryFlag=False):\n",
    "    if binaryFlag:\n",
    "        print('binary on...')\n",
    "\n",
    "    dataset_test = Binary_DeepSurvDataset(BertVocab['token2idx'], valid, global_params['max_len_seq'], max_age=110, year=True, age_symbol=None, min_visit=5)\n",
    "\n",
    "    dl_test = DataLoader(dataset_test, global_params['batch_size']*4, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "    y = []\n",
    "    y_label = []\n",
    "    loss_temp = 0\n",
    "    model.binary=binaryFlag\n",
    "    y_time = []\n",
    "    \n",
    "    for step, batch in enumerate(dl_test):\n",
    "        model.eval()\n",
    "\n",
    "        \n",
    "        age_ids, input_ids, posi_ids, segment_ids, attMask, time2event, label, labelfloat = batch\n",
    "\n",
    "        age_ids = age_ids.to(global_params['device'])\n",
    "        input_ids = input_ids.to(global_params['device'])\n",
    "        posi_ids = posi_ids.to(global_params['device'])\n",
    "        segment_ids = segment_ids.to(global_params['device'])\n",
    "        attMask = attMask.to(global_params['device'])\n",
    "        time2event = time2event.to(global_params['device'])\n",
    "        label = label.to(global_params['device'])\n",
    "        labelfloat = labelfloat.to(global_params['device'])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits , loss= model(input_ids, age_ids, segment_ids, posi_ids, attMask, label,labelfloat, time2event)\n",
    "\n",
    "        logits = logits.cpu()\n",
    "        labelfloat = labelfloat.cpu()\n",
    "        time2event = time2event.cpu()\n",
    "        if step % 50 == 0:\n",
    "            print(step)\n",
    "        y_label.append(labelfloat)\n",
    "        y.append(logits)\n",
    "        y_time.append(time2event)\n",
    "        loss_temp = loss_temp+loss.item()\n",
    "    y_label = torch.cat(y_label, dim=0)\n",
    "    y = torch.exp(torch.cat(y, dim=0))\n",
    "    y_time = torch.cat(y_time, dim=0)\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "    return y_label, y, y_time\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def trainloop_bh(binaryFlag=False, traind=None):\n",
    "    if traind is not None:\n",
    "        train = traind\n",
    "    if binaryFlag:\n",
    "        print('binary on...')\n",
    "\n",
    "    dataset_test = Binary_DeepSurvDataset(BertVocab['token2idx'], train, global_params['max_len_seq'], max_age=110, year=True, age_symbol=None, min_visit=5)\n",
    "\n",
    "\n",
    "    dl_test = DataLoader(dataset_test, int(global_params['batch_size']*2.5), shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "    y = []\n",
    "    y_label = []\n",
    "    loss_temp = 0\n",
    "    model.binary=binaryFlag\n",
    "    y_time = []\n",
    "    \n",
    "    for step, batch in enumerate(dl_test):\n",
    "        model.eval()\n",
    "\n",
    "        \n",
    "        age_ids, input_ids, posi_ids, segment_ids, attMask, time2event, label, labelfloat = batch\n",
    "\n",
    "        age_ids = age_ids.to(global_params['device'])\n",
    "        input_ids = input_ids.to(global_params['device'])\n",
    "        posi_ids = posi_ids.to(global_params['device'])\n",
    "        segment_ids = segment_ids.to(global_params['device'])\n",
    "        attMask = attMask.to(global_params['device'])\n",
    "        time2event = time2event.to(global_params['device'])\n",
    "        label = label.to(global_params['device'])\n",
    "        labelfloat = labelfloat.to(global_params['device'])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits , loss= model(input_ids, age_ids, segment_ids, posi_ids, attMask, label,labelfloat, time2event)\n",
    "\n",
    "        logits = logits.cpu()\n",
    "        labelfloat = labelfloat.cpu()\n",
    "        time2event = time2event.cpu()\n",
    "        if step % 50 == 0:\n",
    "            print(step)\n",
    "        y_label.append(labelfloat)\n",
    "        y.append(logits)\n",
    "        y_time.append(time2event)\n",
    "        loss_temp = loss_temp+loss.item()\n",
    "    y_label = torch.cat(y_label, dim=0)\n",
    "    y = torch.exp(torch.cat(y, dim=0))\n",
    "    y_time = torch.cat(y_time, dim=0)\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "    return y_label, y, y_time\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def adam2(params, config=None):\n",
    "    if config is None:\n",
    "        config = {\n",
    "            'lr': 3e-5,\n",
    "            'warmup_proportion': 0.1\n",
    "        }\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight', 'Eps','VAE']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in params if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in params if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "    optim = Bert.optimization.BertAdam(optimizer_grouped_parameters,\n",
    "                                       lr=config['lr'],\n",
    "                                       warmup=config['warmup_proportion'])\n",
    "    return optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run binary prediction first..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "global_params = {\n",
    "    'batch_size': 224,\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'num_train_epochs': 3,\n",
    "    'device': 'cuda:0',\n",
    "    'output_dir': \"SavedModels/\",\n",
    "    'save_model': True,\n",
    "    'max_len_seq': 512,\n",
    "    'max_age': 110,\n",
    "    'age_year': False,\n",
    "    'age_symbol': None,\n",
    "    'fac': 0.1,\n",
    "    'diseaseI': 1,\n",
    "    'treatments': 2,\n",
    "    \n",
    "\n",
    "}\n",
    "BINFLAG = True\n",
    "\n",
    "\n",
    "trainpat= load_obj('Data/trainset')\n",
    "testpat= load_obj('Data/testset')\n",
    "validpat= load_obj('Data/validset')\n",
    "\n",
    "optim_config = {\n",
    "    'lr': 3e-5,\n",
    "    'warmup_proportion': 0.1,\n",
    "\n",
    "\n",
    "}\n",
    "data = pd.read_parquet('test.parquet/')\n",
    "data['time2event']= 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BertVocab = {}\n",
    "token2idx = {'MASK': 4,\n",
    "  'CLS': 3,\n",
    "  'SEP': 2,\n",
    "  'UNK': 1,\n",
    "  'PAD': 0,\n",
    "            'disease1':5,\n",
    "             'disease2':6,\n",
    "             'disease3':7,\n",
    "             'disease4':8,\n",
    "             'disease5':9,\n",
    "             'disease6':10,\n",
    "             'medication1':11,\n",
    "             'medication2':12,\n",
    "             'medication3':13,\n",
    "             'medication4':14,\n",
    "             'medication5':15,\n",
    "             'medication6':16,\n",
    "            }\n",
    "idx2token = {}\n",
    "for x in token2idx:\n",
    "    idx2token[token2idx[x]]=x\n",
    "BertVocab['token2idx']= token2idx\n",
    "BertVocab['idx2token']= idx2token"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ageVocab, _ = age_vocab(max_age=global_params['max_age'], year=True,\n",
    "                        symbol=global_params['age_symbol'])\n",
    "\n",
    "\n",
    "\n",
    "create_folder(global_params['output_dir'])\n",
    "model_config = {\n",
    "    'vocab_size': len(BertVocab['token2idx'].keys()),  # number of disease + symbols for word embedding\n",
    "    'hidden_size': 150,  # word embedding and seg embedding hidden size\n",
    "    'seg_vocab_size': 2,  # number of vocab for seg embedding\n",
    "    'age_vocab_size': len(ageVocab.keys()),  # number of vocab for age embedding\n",
    "    'max_position_embedding': global_params['max_len_seq'],  # maximum number of tokens\n",
    "    'hidden_dropout_prob': 0.3,  # dropout rate\n",
    "    'num_hidden_layers': 6,  # number of multi-head attention layers required\n",
    "    'num_attention_heads': 6,  # number of attention heads\n",
    "    'attention_probs_dropout_prob': 0.4,  # multi-head attention dropout rate\n",
    "    'intermediate_size': 108,  # the size of the \"intermediate\" layer in the transformer encoder\n",
    "    'hidden_act': 'gelu',\n",
    "    'initializer_range': 0.02,  # parameter weight initializer range\n",
    "    'num_treatment': global_params['treatments'],\n",
    "    'device': global_params['device'],\n",
    "    'concat_embeddings' : True,\n",
    "\n",
    "    \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403775 403775\n"
     ]
    }
   ],
   "source": [
    "cutiter= 0\n",
    "\n",
    "\n",
    "train = data[data.patid.isin(trainpat)].reset_index(drop=True)\n",
    "test = data[data.patid.isin(testpat)].reset_index(drop=True)\n",
    "valid = data[data.patid.isin(validpat)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(len(data), len(list(trainpat) + list(testpat) + list(validpat)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(273954, 30439, 99382, 403775)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test), len(valid), len(train) +  len(test) + len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 4124,\n",
       " 'hidden_size': 150,\n",
       " 'seg_vocab_size': 2,\n",
       " 'age_vocab_size': 1322,\n",
       " 'max_position_embedding': 512,\n",
       " 'hidden_dropout_prob': 0.3,\n",
       " 'num_hidden_layers': 6,\n",
       " 'num_attention_heads': 6,\n",
       " 'attention_probs_dropout_prob': 0.4,\n",
       " 'intermediate_size': 108,\n",
       " 'hidden_act': 'gelu',\n",
       " 'initializer_range': 0.02,\n",
       " 'num_treatment': 2,\n",
       " 'device': 'cuda:0',\n",
       " 'concat_embeddings': True}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 150\n",
      "turn on concat - cehrt structure - embeddings\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "# optim_config = {\n",
    "#     'lr': 5e-5,\n",
    "#     'warmup_proportion': 0.1,\n",
    "#     'weight_decay': 0.5\n",
    "# }\n",
    "# optim = optimizer.adam2(params=list(model.named_parameters()), config=optim_config)\n",
    "# auc, time_cost = evaluation()\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "aurocbest = []\n",
    "auprcbest = []\n",
    "\n",
    "\n",
    "\n",
    "conf = BertConfig(model_config)\n",
    "\n",
    "model = BEHRT_DeepSurv(conf, num_labels=1)\n",
    "\n",
    "# auc, roc, time_cost = evaluation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight\n",
      "bert.embeddings.segment_embeddings.weight\n",
      "bert.embeddings.age_embeddings.weight\n",
      "bert.embeddings.posi_embeddings.weight\n",
      "bert.embeddings.LayerNorm.weight\n",
      "bert.embeddings.LayerNorm.bias\n",
      "bert.embeddings.catmap.weight\n",
      "bert.embeddings.catmap.bias\n",
      "bert.encoder.layer.0.attention.self.query.weight\n",
      "bert.encoder.layer.0.attention.self.query.bias\n",
      "bert.encoder.layer.0.attention.self.key.weight\n",
      "bert.encoder.layer.0.attention.self.key.bias\n",
      "bert.encoder.layer.0.attention.self.value.weight\n",
      "bert.encoder.layer.0.attention.self.value.bias\n",
      "bert.encoder.layer.0.attention.output.dense.weight\n",
      "bert.encoder.layer.0.attention.output.dense.bias\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.0.intermediate.dense.weight\n",
      "bert.encoder.layer.0.intermediate.dense.bias\n",
      "bert.encoder.layer.0.output.dense.weight\n",
      "bert.encoder.layer.0.output.dense.bias\n",
      "bert.encoder.layer.0.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.attention.self.query.weight\n",
      "bert.encoder.layer.1.attention.self.query.bias\n",
      "bert.encoder.layer.1.attention.self.key.weight\n",
      "bert.encoder.layer.1.attention.self.key.bias\n",
      "bert.encoder.layer.1.attention.self.value.weight\n",
      "bert.encoder.layer.1.attention.self.value.bias\n",
      "bert.encoder.layer.1.attention.output.dense.weight\n",
      "bert.encoder.layer.1.attention.output.dense.bias\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.intermediate.dense.weight\n",
      "bert.encoder.layer.1.intermediate.dense.bias\n",
      "bert.encoder.layer.1.output.dense.weight\n",
      "bert.encoder.layer.1.output.dense.bias\n",
      "bert.encoder.layer.1.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.attention.self.query.weight\n",
      "bert.encoder.layer.2.attention.self.query.bias\n",
      "bert.encoder.layer.2.attention.self.key.weight\n",
      "bert.encoder.layer.2.attention.self.key.bias\n",
      "bert.encoder.layer.2.attention.self.value.weight\n",
      "bert.encoder.layer.2.attention.self.value.bias\n",
      "bert.encoder.layer.2.attention.output.dense.weight\n",
      "bert.encoder.layer.2.attention.output.dense.bias\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.intermediate.dense.weight\n",
      "bert.encoder.layer.2.intermediate.dense.bias\n",
      "bert.encoder.layer.2.output.dense.weight\n",
      "bert.encoder.layer.2.output.dense.bias\n",
      "bert.encoder.layer.2.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.attention.self.query.weight\n",
      "bert.encoder.layer.3.attention.self.query.bias\n",
      "bert.encoder.layer.3.attention.self.key.weight\n",
      "bert.encoder.layer.3.attention.self.key.bias\n",
      "bert.encoder.layer.3.attention.self.value.weight\n",
      "bert.encoder.layer.3.attention.self.value.bias\n",
      "bert.encoder.layer.3.attention.output.dense.weight\n",
      "bert.encoder.layer.3.attention.output.dense.bias\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.intermediate.dense.weight\n",
      "bert.encoder.layer.3.intermediate.dense.bias\n",
      "bert.encoder.layer.3.output.dense.weight\n",
      "bert.encoder.layer.3.output.dense.bias\n",
      "bert.encoder.layer.3.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.attention.self.query.weight\n",
      "bert.encoder.layer.4.attention.self.query.bias\n",
      "bert.encoder.layer.4.attention.self.key.weight\n",
      "bert.encoder.layer.4.attention.self.key.bias\n",
      "bert.encoder.layer.4.attention.self.value.weight\n",
      "bert.encoder.layer.4.attention.self.value.bias\n",
      "bert.encoder.layer.4.attention.output.dense.weight\n",
      "bert.encoder.layer.4.attention.output.dense.bias\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.intermediate.dense.weight\n",
      "bert.encoder.layer.4.intermediate.dense.bias\n",
      "bert.encoder.layer.4.output.dense.weight\n",
      "bert.encoder.layer.4.output.dense.bias\n",
      "bert.encoder.layer.4.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.attention.self.query.weight\n",
      "bert.encoder.layer.5.attention.self.query.bias\n",
      "bert.encoder.layer.5.attention.self.key.weight\n",
      "bert.encoder.layer.5.attention.self.key.bias\n",
      "bert.encoder.layer.5.attention.self.value.weight\n",
      "bert.encoder.layer.5.attention.self.value.bias\n",
      "bert.encoder.layer.5.attention.output.dense.weight\n",
      "bert.encoder.layer.5.attention.output.dense.bias\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.intermediate.dense.weight\n",
      "bert.encoder.layer.5.intermediate.dense.bias\n",
      "bert.encoder.layer.5.output.dense.weight\n",
      "bert.encoder.layer.5.output.dense.bias\n",
      "bert.encoder.layer.5.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.output.LayerNorm.bias\n",
      "bert.pooler.dense.weight\n",
      "bert.pooler.dense.bias\n",
      "classifier.weight\n",
      "classifier.bias\n"
     ]
    }
   ],
   "source": [
    "pre_bert = os.path.join('/gpfs3/well/rahimi/users/gra027/JNb/general_model_newCutCPRD/SavedModels/',\n",
    "                                 \"MLM_CEHR_newcut1985_2020_DMProc__6msummary.bin\")\n",
    "\n",
    "\n",
    "pretrained_dict = torch.load(pre_bert, map_location='cpu')\n",
    "modeld = model.state_dict()\n",
    "for dictWeight in modeld:\n",
    "    dictWeightsub = dictWeight\n",
    "    print(dictWeightsub)\n",
    "    #         print(dictWeightsub)\n",
    "    if dictWeightsub in pretrained_dict and dictWeightsub not in ['bert.embeddings.catmap.weight', 'bert.embeddings.catmap.bias',  'bert.embeddings.posi_embeddings.weight']:\n",
    "        modeld[dictWeight] = pretrained_dict[dictWeightsub]\n",
    "    elif dictWeight in pretrained_dict and 'cls' in dictWeight:\n",
    "        modeld[dictWeight] = pretrained_dict[dictWeight]\n",
    "numPos = model_config['max_position_embedding']\n",
    "if model_config['max_position_embedding'] > 250:\n",
    "    numPos = 250\n",
    "modeld['bert.embeddings.posi_embeddings.weight'][:numPos] = pretrained_dict[\n",
    "                                                                     'bert.embeddings.posi_embeddings.weight'][\n",
    "                                                                 :numPos]\n",
    "\n",
    "model.load_state_dict(modeld)\n",
    "\n",
    "model = model.to(global_params['device'])\n",
    "optim = adam2(params=list(model.named_parameters()), config=optim_config)\n",
    "model.binary = BINFLAG\n",
    "\n",
    "scheduler = toptimizer.lr_scheduler.ExponentialLR(optim, 0.95, last_epoch=-1)\n",
    "patience = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary on...\n",
      "epoch: 0\t| Cnt: 1\t| Loss: 0.0070767349004745485\t| precision: 0.25755369822528995\n",
      "epoch: 0\t| Cnt: 101\t| Loss: 0.6346148502826691\t| precision: 0.3024541357300482\n",
      "epoch: 0\t| Cnt: 201\t| Loss: 0.5947180128097534\t| precision: 0.6043179811708665\n",
      "epoch: 0\t| Cnt: 301\t| Loss: 0.5719782993197441\t| precision: 0.500210617573104\n",
      "epoch: 0\t| Cnt: 401\t| Loss: 0.554108974635601\t| precision: 0.5095252866485129\n",
      "epoch: 0\t| Cnt: 501\t| Loss: 0.5529410451650619\t| precision: 0.5348001345486142\n",
      "epoch: 0\t| Cnt: 601\t| Loss: 0.5517038303613663\t| precision: 0.5189245010372551\n",
      "epoch: 0\t| Cnt: 701\t| Loss: 0.53964546084404\t| precision: 0.5255610671743958\n",
      "epoch: 0\t| Cnt: 801\t| Loss: 0.5442788770794869\t| precision: 0.4695545580730964\n",
      "epoch: 0\t| Cnt: 901\t| Loss: 0.5423697191476822\t| precision: 0.5907113314066799\n",
      "epoch: 0\t| Cnt: 1001\t| Loss: 0.5386657160520554\t| precision: 0.5835202658728285\n",
      "epoch: 0\t| Cnt: 1101\t| Loss: 0.5351114597916603\t| precision: 0.590581286616105\n",
      "epoch: 0\t| Cnt: 1201\t| Loss: 0.5285422003269196\t| precision: 0.5703387697609468\n",
      "binary on...\n",
      "0\n",
      "50\n",
      "100\n",
      "** ** * Saving best fine - tuned model ** ** * \n",
      "loss: 71.43504393100739, prc : 0.5879088842421847, auroc : 0.7694643073123544\n",
      "binary on...\n",
      "epoch: 1\t| Cnt: 1\t| Loss: 0.005037664771080017\t| precision: 0.5824207314494714\n",
      "epoch: 1\t| Cnt: 101\t| Loss: 0.5357456824183464\t| precision: 0.6225615981905205\n",
      "epoch: 1\t| Cnt: 201\t| Loss: 0.5278237691521644\t| precision: 0.7201914125909039\n",
      "epoch: 1\t| Cnt: 301\t| Loss: 0.5239689275622368\t| precision: 0.7468343526607697\n",
      "epoch: 1\t| Cnt: 401\t| Loss: 0.5256247115135193\t| precision: 0.5713122640132338\n",
      "epoch: 1\t| Cnt: 501\t| Loss: 0.5252440658211708\t| precision: 0.5219794681456581\n",
      "epoch: 1\t| Cnt: 601\t| Loss: 0.5303474804759025\t| precision: 0.6215488800122563\n",
      "epoch: 1\t| Cnt: 701\t| Loss: 0.5216967436671257\t| precision: 0.6582182892818402\n",
      "epoch: 1\t| Cnt: 801\t| Loss: 0.521835962831974\t| precision: 0.6211001712288149\n",
      "epoch: 1\t| Cnt: 901\t| Loss: 0.522396849989891\t| precision: 0.6291506667694133\n",
      "epoch: 1\t| Cnt: 1001\t| Loss: 0.524601816534996\t| precision: 0.6901333356389224\n",
      "epoch: 1\t| Cnt: 1101\t| Loss: 0.5205426144599915\t| precision: 0.5595954361456601\n",
      "epoch: 1\t| Cnt: 1201\t| Loss: 0.52726538002491\t| precision: 0.5980175887366599\n",
      "binary on...\n",
      "0\n",
      "50\n",
      "100\n",
      "** ** * Saving best fine - tuned model ** ** * \n",
      "loss: 71.13374936580658, prc : 0.5965111838203356, auroc : 0.7739913656022991\n",
      "binary on...\n",
      "epoch: 2\t| Cnt: 1\t| Loss: 0.0048958522081375124\t| precision: 0.6302584893734983\n",
      "epoch: 2\t| Cnt: 101\t| Loss: 0.5225693187117577\t| precision: 0.6497502372470481\n",
      "epoch: 2\t| Cnt: 201\t| Loss: 0.5187896934151649\t| precision: 0.6636144456868136\n",
      "epoch: 2\t| Cnt: 301\t| Loss: 0.5192484012246132\t| precision: 0.6268475848877986\n",
      "epoch: 2\t| Cnt: 401\t| Loss: 0.5207659304141998\t| precision: 0.6412817191284046\n",
      "epoch: 2\t| Cnt: 501\t| Loss: 0.5164548435807228\t| precision: 0.5954934235763898\n",
      "epoch: 2\t| Cnt: 601\t| Loss: 0.5215364128351212\t| precision: 0.5907430552356724\n",
      "epoch: 2\t| Cnt: 701\t| Loss: 0.5175038284063339\t| precision: 0.5204511597987396\n",
      "epoch: 2\t| Cnt: 801\t| Loss: 0.5246468847990036\t| precision: 0.5648163890666199\n",
      "epoch: 2\t| Cnt: 901\t| Loss: 0.5116319844126701\t| precision: 0.6806451286408363\n",
      "epoch: 2\t| Cnt: 1001\t| Loss: 0.519018594622612\t| precision: 0.703004525207909\n",
      "epoch: 2\t| Cnt: 1101\t| Loss: 0.5154127594828606\t| precision: 0.5981013838198483\n",
      "epoch: 2\t| Cnt: 1201\t| Loss: 0.5188450393080711\t| precision: 0.5794385466745449\n",
      "binary on...\n",
      "0\n",
      "50\n",
      "100\n",
      "** ** * Saving best fine - tuned model ** ** * \n",
      "loss: 70.84173926711082, prc : 0.6041909285269225, auroc : 0.7769824730445687\n",
      "binary on...\n",
      "epoch: 3\t| Cnt: 1\t| Loss: 0.004880310595035553\t| precision: 0.6109254538757501\n",
      "epoch: 3\t| Cnt: 101\t| Loss: 0.5160335510969162\t| precision: 0.6792095960326832\n",
      "epoch: 3\t| Cnt: 201\t| Loss: 0.5178394302725792\t| precision: 0.6562097268071034\n",
      "epoch: 3\t| Cnt: 301\t| Loss: 0.5142235776782036\t| precision: 0.5559444456458853\n",
      "epoch: 3\t| Cnt: 401\t| Loss: 0.5149957266449928\t| precision: 0.48589554016348774\n",
      "epoch: 3\t| Cnt: 501\t| Loss: 0.5171974533796311\t| precision: 0.6160437726133962\n",
      "epoch: 3\t| Cnt: 601\t| Loss: 0.5200849142670632\t| precision: 0.6357891946410685\n",
      "epoch: 3\t| Cnt: 701\t| Loss: 0.5090760537981986\t| precision: 0.6503944866481828\n",
      "epoch: 3\t| Cnt: 801\t| Loss: 0.5097729969024658\t| precision: 0.5905963569881539\n",
      "epoch: 3\t| Cnt: 901\t| Loss: 0.5133080235123635\t| precision: 0.6587281226849218\n",
      "epoch: 3\t| Cnt: 1001\t| Loss: 0.5168034172058106\t| precision: 0.6873777165609218\n",
      "epoch: 3\t| Cnt: 1101\t| Loss: 0.5110053294897079\t| precision: 0.5774708554681219\n",
      "epoch: 3\t| Cnt: 1201\t| Loss: 0.522167654633522\t| precision: 0.6592727911839901\n",
      "binary on...\n",
      "0\n",
      "50\n",
      "100\n",
      "** ** * Saving best fine - tuned model ** ** * \n",
      "loss: 70.69385355710983, prc : 0.6091291230317546, auroc : 0.7804175040309393\n",
      "binary on...\n",
      "epoch: 4\t| Cnt: 1\t| Loss: 0.00515207588672638\t| precision: 0.548588255049472\n",
      "epoch: 4\t| Cnt: 101\t| Loss: 0.5123394331336022\t| precision: 0.6429419310101385\n",
      "epoch: 4\t| Cnt: 201\t| Loss: 0.5142805975675583\t| precision: 0.6645157665802273\n",
      "epoch: 4\t| Cnt: 301\t| Loss: 0.5090723562240601\t| precision: 0.6298552603651855\n",
      "epoch: 4\t| Cnt: 401\t| Loss: 0.5146846225857735\t| precision: 0.6319027408277078\n",
      "epoch: 4\t| Cnt: 501\t| Loss: 0.5099833279848098\t| precision: 0.5986810911124909\n",
      "epoch: 4\t| Cnt: 601\t| Loss: 0.5117739710211754\t| precision: 0.5848424224467409\n",
      "epoch: 4\t| Cnt: 701\t| Loss: 0.5152322620153427\t| precision: 0.5940305162779833\n",
      "epoch: 4\t| Cnt: 801\t| Loss: 0.5141735136508941\t| precision: 0.5653994028321355\n",
      "epoch: 4\t| Cnt: 901\t| Loss: 0.512006596326828\t| precision: 0.6889830930302872\n",
      "epoch: 4\t| Cnt: 1001\t| Loss: 0.5117217043042183\t| precision: 0.4464233418947643\n",
      "epoch: 4\t| Cnt: 1101\t| Loss: 0.5076319685578347\t| precision: 0.5277593754547037\n",
      "epoch: 4\t| Cnt: 1201\t| Loss: 0.5113385882973671\t| precision: 0.5456771346250356\n",
      "binary on...\n",
      "0\n",
      "50\n",
      "100\n",
      "0\n",
      "loss: 70.43414786458015, prc : 0.6106081594496959, auroc : 0.7803894588460638\n",
      "binary on...\n",
      "epoch: 5\t| Cnt: 1\t| Loss: 0.005003929138183594\t| precision: 0.6436665048469881\n",
      "epoch: 5\t| Cnt: 101\t| Loss: 0.5040783101320266\t| precision: 0.6608596012934294\n",
      "epoch: 5\t| Cnt: 201\t| Loss: 0.511174981892109\t| precision: 0.5839481953463109\n",
      "epoch: 5\t| Cnt: 301\t| Loss: 0.5130080783367157\t| precision: 0.5735569735359529\n",
      "epoch: 5\t| Cnt: 401\t| Loss: 0.5124362635612488\t| precision: 0.6494099438540172\n",
      "epoch: 5\t| Cnt: 501\t| Loss: 0.5104469609260559\t| precision: 0.6231708080818703\n",
      "epoch: 5\t| Cnt: 601\t| Loss: 0.5095859107375145\t| precision: 0.7718699220851103\n",
      "epoch: 5\t| Cnt: 701\t| Loss: 0.5123184645175933\t| precision: 0.647591652425539\n",
      "epoch: 5\t| Cnt: 801\t| Loss: 0.5060137644410133\t| precision: 0.6185772850656045\n",
      "epoch: 5\t| Cnt: 901\t| Loss: 0.5120018723607064\t| precision: 0.5933952806970442\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-28-5b0e384e4d0c>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mbestauroc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0me\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m50\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m     \u001B[0mfullCounter\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrainloop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mBINFLAG\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[0mprc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mauroc\u001B[0m \u001B[0;34m,\u001B[0m\u001B[0mloss_temp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mevaluationloop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mBINFLAG\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-3-f43316a34a28>\u001B[0m in \u001B[0;36mtrainloop\u001B[0;34m(e, binaryFlag)\u001B[0m\n\u001B[1;32m     22\u001B[0m     \u001B[0mcnt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 24\u001B[0;31m     \u001B[0;32mfor\u001B[0m \u001B[0mstep\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdl_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     25\u001B[0m         \u001B[0mcnt\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/well/rahimi/users/gra027/conda/envs/pytorch_upgrade/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    515\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sampler_iter\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    516\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 517\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    518\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    519\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[0;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/well/rahimi/users/gra027/conda/envs/pytorch_upgrade/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    555\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    556\u001B[0m         \u001B[0mindex\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 557\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_fetcher\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    558\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    559\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/well/rahimi/users/gra027/conda/envs/pytorch_upgrade/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001B[0m in \u001B[0;36mfetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 44\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     45\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/well/rahimi/users/gra027/conda/envs/pytorch_upgrade/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 44\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     45\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/gpfs3/well/rahimi/users/gra027/JNb/HORIZON/CVmortalityPred_inHF/ModelPkg/Data_Deterministic.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, index)\u001B[0m\n\u001B[1;32m    212\u001B[0m         \u001B[0mtokens\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mseq_padding\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtokens\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax_len\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    213\u001B[0m         \u001B[0mposition\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mposition_idx\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtokens\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 214\u001B[0;31m         \u001B[0msegment\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mindex_seg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtokens\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    215\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    216\u001B[0m         \u001B[0;31m# pad code and label\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/gpfs3/well/rahimi/users/gra027/JNb/HORIZON/CVmortalityPred_inHF/ModelPkg/utils.py\u001B[0m in \u001B[0;36mindex_seg\u001B[0;34m(tokens, symbol)\u001B[0m\n\u001B[1;32m    517\u001B[0m                 \u001B[0mflag\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    518\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 519\u001B[0;31m             \u001B[0mseg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mflag\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    520\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mseg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    521\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "auprcbest =[]\n",
    "aurocbest = []\n",
    "best_pre = -1\n",
    "patience = 0\n",
    "bestauroc = -1\n",
    "for e in range(50):\n",
    "    fullCounter = trainloop(e, BINFLAG)\n",
    "\n",
    "    prc, auroc ,loss_temp = evaluationloop(BINFLAG)\n",
    "    fullCounter = fullCounter+1\n",
    "\n",
    "    if auroc > bestauroc:\n",
    "        patience=0\n",
    "        # Save a trained model\n",
    "        print(\"** ** * Saving best fine - tuned model ** ** * \")\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "        output_model_file = os.path.join(global_params['output_dir'],  'binarypredTrisk.bin')\n",
    "        create_folder(global_params['output_dir'])\n",
    "        if global_params['save_model']:\n",
    "            torch.save(model_to_save.state_dict(), output_model_file)\n",
    "\n",
    "        best_pre = prc\n",
    "        bestauroc = auroc\n",
    "    else:\n",
    "        if patience % 2 == 0 and patience != 0:\n",
    "            scheduler.step()\n",
    "            print(\"LR: \", scheduler.get_lr())\n",
    "\n",
    "        if patience >=3 and patience != 0:\n",
    "            print('quitting... no gains...')\n",
    "            break\n",
    "        print(patience)\n",
    "        patience = patience + 1\n",
    "    print('loss: {}, prc : {}, auroc : {}'.format(loss_temp, prc, auroc))\n",
    "print('best ever auroc: ', bestauroc)\n",
    "print('best ever auprc: ', best_pre)\n",
    "\n",
    "auprcbest.append(best_pre)\n",
    "aurocbest.append(bestauroc)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# surv modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "global_params = {\n",
    "    'batch_size': 224,\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'num_train_epochs': 3,\n",
    "    'device': 'cuda:0',\n",
    "    'output_dir': \"SavedModels/\",\n",
    "    'save_model': True,\n",
    "    'max_len_seq': 512,\n",
    "    'max_age': 110,\n",
    "    'age_year': False,\n",
    "    'age_symbol': None,\n",
    "    'fac': 0.1,\n",
    "    'diseaseI': 1,\n",
    "    'treatments': 2,\n",
    "    \n",
    "\n",
    "}\n",
    "BINFLAG = False\n",
    "\n",
    "trainpat= load_obj('Data/trainset')\n",
    "testpat= load_obj('Data/testset')\n",
    "validpat= load_obj('Data/validset')\n",
    "\n",
    "\n",
    "data = pd.read_parquet('test.parquet/')\n",
    "data['time2event']= 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ageVocab, _ = age_vocab(max_age=global_params['max_age'], year=True,\n",
    "                        symbol=global_params['age_symbol'])\n",
    "\n",
    "\n",
    "ageVocab, _ = age_vocab(max_age=global_params['max_age'], year=global_params['age_year'],\n",
    "                        symbol=global_params['age_symbol'])\n",
    "\n",
    "create_folder(global_params['output_dir'])\n",
    "model_config = {\n",
    "    'vocab_size': len(BertVocab['token2idx'].keys()),  # number of disease + symbols for word embedding\n",
    "    'hidden_size': 150,  # word embedding and seg embedding hidden size\n",
    "    'seg_vocab_size': 2,  # number of vocab for seg embedding\n",
    "    'age_vocab_size': len(ageVocab.keys()),  # number of vocab for age embedding\n",
    "    'max_position_embedding': global_params['max_len_seq'],  # maximum number of tokens\n",
    "    'hidden_dropout_prob': 0.3,  # dropout rate\n",
    "    'num_hidden_layers': 6,  # number of multi-head attention layers required\n",
    "    'num_attention_heads': 6,  # number of attention heads\n",
    "    'attention_probs_dropout_prob': 0.4,  # multi-head attention dropout rate\n",
    "    'intermediate_size': 108,  # the size of the \"intermediate\" layer in the transformer encoder\n",
    "    'hidden_act': 'gelu',\n",
    "    'initializer_range': 0.02,  # parameter weight initializer range\n",
    "    'num_treatment': global_params['treatments'],\n",
    "    'device': global_params['device'],\n",
    "    'concat_embeddings' : True,\n",
    "\n",
    "    \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_config = {\n",
    "    'lr':8e-5, \n",
    "#     'weight_decay': 0.01, \n",
    "    'warmup_proportion': 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403775 403775\n"
     ]
    }
   ],
   "source": [
    "cutiter= 0\n",
    "\n",
    "\n",
    "\n",
    "train = data[data.patid.isin(trainpat)].reset_index(drop=True)\n",
    "test = data[data.patid.isin(testpat)].reset_index(drop=True)\n",
    "valid = data[data.patid.isin(validpat)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "print(len(data), len(list(trainpat) + list(testpat) + list(validpat)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(273954, 30439, 99382, 403775)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test), len(valid), len(train) +  len(test) + len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(set(), set(), set())"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train.patid.values).intersection(set(test.patid.values)), set(valid.patid.values).intersection(set(test.patid.values)), set(train.patid.values).intersection(set(valid.patid.values))\n",
    "\n",
    "# check if 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turn on concat - cehrt structure - embeddings\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "aurocbest = []\n",
    "auprcbest = []\n",
    "\n",
    "\n",
    "\n",
    "conf = BertConfig(model_config)\n",
    "\n",
    "model = BEHRT_DeepSurv(conf, num_labels=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def adam_surv(params, config=None):\n",
    "    if config is None:\n",
    "        config = {\n",
    "            'lr': 3e-5,\n",
    "            'warmup_proportion': 0.1\n",
    "        }\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight', 'Eps','VAE']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in params if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in params if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "    optim = Bert.optimization.BertAdam(optimizer_grouped_parameters,\n",
    "                                       lr=config['lr'],\n",
    "                                       warmup=config['warmup_proportion'])\n",
    "    return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight\n",
      "bert.embeddings.segment_embeddings.weight\n",
      "bert.embeddings.age_embeddings.weight\n",
      "bert.embeddings.posi_embeddings.weight\n",
      "bert.embeddings.LayerNorm.weight\n",
      "bert.embeddings.LayerNorm.bias\n",
      "bert.embeddings.catmap.weight\n",
      "bert.embeddings.catmap.bias\n",
      "bert.encoder.layer.0.attention.self.query.weight\n",
      "bert.encoder.layer.0.attention.self.query.bias\n",
      "bert.encoder.layer.0.attention.self.key.weight\n",
      "bert.encoder.layer.0.attention.self.key.bias\n",
      "bert.encoder.layer.0.attention.self.value.weight\n",
      "bert.encoder.layer.0.attention.self.value.bias\n",
      "bert.encoder.layer.0.attention.output.dense.weight\n",
      "bert.encoder.layer.0.attention.output.dense.bias\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.0.intermediate.dense.weight\n",
      "bert.encoder.layer.0.intermediate.dense.bias\n",
      "bert.encoder.layer.0.output.dense.weight\n",
      "bert.encoder.layer.0.output.dense.bias\n",
      "bert.encoder.layer.0.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.attention.self.query.weight\n",
      "bert.encoder.layer.1.attention.self.query.bias\n",
      "bert.encoder.layer.1.attention.self.key.weight\n",
      "bert.encoder.layer.1.attention.self.key.bias\n",
      "bert.encoder.layer.1.attention.self.value.weight\n",
      "bert.encoder.layer.1.attention.self.value.bias\n",
      "bert.encoder.layer.1.attention.output.dense.weight\n",
      "bert.encoder.layer.1.attention.output.dense.bias\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.intermediate.dense.weight\n",
      "bert.encoder.layer.1.intermediate.dense.bias\n",
      "bert.encoder.layer.1.output.dense.weight\n",
      "bert.encoder.layer.1.output.dense.bias\n",
      "bert.encoder.layer.1.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.attention.self.query.weight\n",
      "bert.encoder.layer.2.attention.self.query.bias\n",
      "bert.encoder.layer.2.attention.self.key.weight\n",
      "bert.encoder.layer.2.attention.self.key.bias\n",
      "bert.encoder.layer.2.attention.self.value.weight\n",
      "bert.encoder.layer.2.attention.self.value.bias\n",
      "bert.encoder.layer.2.attention.output.dense.weight\n",
      "bert.encoder.layer.2.attention.output.dense.bias\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.intermediate.dense.weight\n",
      "bert.encoder.layer.2.intermediate.dense.bias\n",
      "bert.encoder.layer.2.output.dense.weight\n",
      "bert.encoder.layer.2.output.dense.bias\n",
      "bert.encoder.layer.2.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.attention.self.query.weight\n",
      "bert.encoder.layer.3.attention.self.query.bias\n",
      "bert.encoder.layer.3.attention.self.key.weight\n",
      "bert.encoder.layer.3.attention.self.key.bias\n",
      "bert.encoder.layer.3.attention.self.value.weight\n",
      "bert.encoder.layer.3.attention.self.value.bias\n",
      "bert.encoder.layer.3.attention.output.dense.weight\n",
      "bert.encoder.layer.3.attention.output.dense.bias\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.intermediate.dense.weight\n",
      "bert.encoder.layer.3.intermediate.dense.bias\n",
      "bert.encoder.layer.3.output.dense.weight\n",
      "bert.encoder.layer.3.output.dense.bias\n",
      "bert.encoder.layer.3.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.attention.self.query.weight\n",
      "bert.encoder.layer.4.attention.self.query.bias\n",
      "bert.encoder.layer.4.attention.self.key.weight\n",
      "bert.encoder.layer.4.attention.self.key.bias\n",
      "bert.encoder.layer.4.attention.self.value.weight\n",
      "bert.encoder.layer.4.attention.self.value.bias\n",
      "bert.encoder.layer.4.attention.output.dense.weight\n",
      "bert.encoder.layer.4.attention.output.dense.bias\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.intermediate.dense.weight\n",
      "bert.encoder.layer.4.intermediate.dense.bias\n",
      "bert.encoder.layer.4.output.dense.weight\n",
      "bert.encoder.layer.4.output.dense.bias\n",
      "bert.encoder.layer.4.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.attention.self.query.weight\n",
      "bert.encoder.layer.5.attention.self.query.bias\n",
      "bert.encoder.layer.5.attention.self.key.weight\n",
      "bert.encoder.layer.5.attention.self.key.bias\n",
      "bert.encoder.layer.5.attention.self.value.weight\n",
      "bert.encoder.layer.5.attention.self.value.bias\n",
      "bert.encoder.layer.5.attention.output.dense.weight\n",
      "bert.encoder.layer.5.attention.output.dense.bias\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.intermediate.dense.weight\n",
      "bert.encoder.layer.5.intermediate.dense.bias\n",
      "bert.encoder.layer.5.output.dense.weight\n",
      "bert.encoder.layer.5.output.dense.bias\n",
      "bert.encoder.layer.5.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.output.LayerNorm.bias\n",
      "bert.pooler.dense.weight\n",
      "bert.pooler.dense.bias\n",
      "classifier.weight\n",
      "classifier.bias\n"
     ]
    }
   ],
   "source": [
    "pre_bert = os.path.join('/gpfs3/well/rahimi/users/gra027/JNb/general_model_newCutCPRD/SavedModels/',\n",
    "                                 \"MLM_CEHR_newcut1985_2020_DMProc__6msummary.bin\")\n",
    "model.load_state_dict(torch.load(pre_bert, map_location='cpu'))\n",
    "\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "# del optimizer\n",
    "for n , param in model.named_parameters():\n",
    "    if '5' in n:\n",
    "        print(n)\n",
    "        param.requires_grad = True\n",
    "model.bert.pooler.dense.weight.requires_grad = True\n",
    "model.bert.pooler.dense.bias.requires_grad = True\n",
    "model.classifier.weight.requires_grad = True\n",
    "model.classifier.bias.requires_grad = True\n",
    "\n",
    "model = model.to(global_params['device'])\n",
    "optim = adam_surv(params=list(model.named_parameters()), config=optim_config)\n",
    "model.binary = BINFLAG\n",
    "\n",
    "\n",
    "scheduler = toptimizer.lr_scheduler.ExponentialLR(optim, 0.95, last_epoch=-1)\n",
    "patience = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\t| Cnt: 1\t| Loss: 0.04930774211883545\t| precision: -1\n",
      "epoch: 0\t| Cnt: 101\t| Loss: 4.623553133010864\t| precision: -1\n",
      "epoch: 0\t| Cnt: 201\t| Loss: 4.474506106376648\t| precision: -1\n",
      "epoch: 0\t| Cnt: 301\t| Loss: 4.4673861885070805\t| precision: -1\n",
      "epoch: 0\t| Cnt: 401\t| Loss: 4.441414451599121\t| precision: -1\n",
      "epoch: 0\t| Cnt: 501\t| Loss: 4.443978734016419\t| precision: -1\n",
      "epoch: 0\t| Cnt: 601\t| Loss: 4.430216579437256\t| precision: -1\n",
      "epoch: 0\t| Cnt: 701\t| Loss: 4.441653504371643\t| precision: -1\n",
      "epoch: 0\t| Cnt: 801\t| Loss: 4.426389131546021\t| precision: -1\n",
      "epoch: 0\t| Cnt: 901\t| Loss: 4.418193845748902\t| precision: -1\n",
      "epoch: 0\t| Cnt: 1001\t| Loss: 4.409481201171875\t| precision: -1\n",
      "epoch: 0\t| Cnt: 1101\t| Loss: 4.40348819732666\t| precision: -1\n",
      "epoch: 0\t| Cnt: 1201\t| Loss: 4.395103621482849\t| precision: -1\n",
      "0\n",
      "50\n",
      "100\n",
      "** ** * Saving best fine - tuned model ** ** * \n",
      "lr:  [8e-05, 8e-05]\n",
      "loss: 606.3943476676941, prc : 0.9156612339944864, auroc : 0.7961325119107817\n",
      "epoch: 1\t| Cnt: 1\t| Loss: 0.044286098480224606\t| precision: -1\n",
      "epoch: 1\t| Cnt: 101\t| Loss: 4.39549843788147\t| precision: -1\n",
      "epoch: 1\t| Cnt: 201\t| Loss: 4.386768460273743\t| precision: -1\n",
      "epoch: 1\t| Cnt: 301\t| Loss: 4.398474059104919\t| precision: -1\n",
      "epoch: 1\t| Cnt: 401\t| Loss: 4.3899429893493656\t| precision: -1\n",
      "epoch: 1\t| Cnt: 501\t| Loss: 4.393977932929992\t| precision: -1\n",
      "epoch: 1\t| Cnt: 601\t| Loss: 4.385460090637207\t| precision: -1\n",
      "epoch: 1\t| Cnt: 701\t| Loss: 4.385185508728028\t| precision: -1\n",
      "epoch: 1\t| Cnt: 801\t| Loss: 4.4033391427993775\t| precision: -1\n",
      "epoch: 1\t| Cnt: 901\t| Loss: 4.387044067382813\t| precision: -1\n",
      "epoch: 1\t| Cnt: 1001\t| Loss: 4.391032176017761\t| precision: -1\n",
      "epoch: 1\t| Cnt: 1101\t| Loss: 4.370596885681152\t| precision: -1\n",
      "epoch: 1\t| Cnt: 1201\t| Loss: 4.387952208518982\t| precision: -1\n",
      "0\n",
      "50\n",
      "100\n",
      "** ** * Saving best fine - tuned model ** ** * \n",
      "lr:  [8e-05, 8e-05]\n",
      "loss: 600.5543923377991, prc : 0.9172061394827248, auroc : 0.8031431299744948\n",
      "epoch: 2\t| Cnt: 1\t| Loss: 0.04349653720855713\t| precision: -1\n",
      "epoch: 2\t| Cnt: 101\t| Loss: 4.375877070426941\t| precision: -1\n",
      "epoch: 2\t| Cnt: 201\t| Loss: 4.377415766716004\t| precision: -1\n",
      "epoch: 2\t| Cnt: 301\t| Loss: 4.37849910736084\t| precision: -1\n",
      "epoch: 2\t| Cnt: 401\t| Loss: 4.3729822540283205\t| precision: -1\n",
      "epoch: 2\t| Cnt: 501\t| Loss: 4.37209032535553\t| precision: -1\n",
      "epoch: 2\t| Cnt: 601\t| Loss: 4.378111553192139\t| precision: -1\n",
      "epoch: 2\t| Cnt: 701\t| Loss: 4.363144998550415\t| precision: -1\n",
      "epoch: 2\t| Cnt: 801\t| Loss: 4.3807656908035275\t| precision: -1\n",
      "epoch: 2\t| Cnt: 901\t| Loss: 4.361532492637634\t| precision: -1\n",
      "epoch: 2\t| Cnt: 1001\t| Loss: 4.375042214393615\t| precision: -1\n",
      "epoch: 2\t| Cnt: 1101\t| Loss: 4.363785390853882\t| precision: -1\n",
      "epoch: 2\t| Cnt: 1201\t| Loss: 4.354551796913147\t| precision: -1\n",
      "0\n",
      "50\n",
      "100\n",
      "** ** * Saving best fine - tuned model ** ** * \n",
      "lr:  [8e-05, 8e-05]\n",
      "loss: 604.8402147293091, prc : 0.9110594968848378, auroc : 0.805495333924085\n",
      "epoch: 3\t| Cnt: 1\t| Loss: 0.04265749931335449\t| precision: -1\n",
      "epoch: 3\t| Cnt: 101\t| Loss: 4.3422993612289424\t| precision: -1\n",
      "epoch: 3\t| Cnt: 201\t| Loss: 4.354872198104858\t| precision: -1\n",
      "epoch: 3\t| Cnt: 301\t| Loss: 4.362014260292053\t| precision: -1\n",
      "epoch: 3\t| Cnt: 401\t| Loss: 4.361534218788147\t| precision: -1\n",
      "epoch: 3\t| Cnt: 501\t| Loss: 4.368329195976258\t| precision: -1\n",
      "epoch: 3\t| Cnt: 601\t| Loss: 4.366454377174377\t| precision: -1\n",
      "epoch: 3\t| Cnt: 701\t| Loss: 4.363270440101624\t| precision: -1\n",
      "epoch: 3\t| Cnt: 801\t| Loss: 4.357308492660523\t| precision: -1\n",
      "epoch: 3\t| Cnt: 901\t| Loss: 4.3623398542404175\t| precision: -1\n",
      "epoch: 3\t| Cnt: 1001\t| Loss: 4.351702342033386\t| precision: -1\n",
      "epoch: 3\t| Cnt: 1101\t| Loss: 4.37114529132843\t| precision: -1\n",
      "epoch: 3\t| Cnt: 1201\t| Loss: 4.3641059827804565\t| precision: -1\n",
      "0\n",
      "50\n",
      "100\n",
      "0\n",
      "lr:  [8e-05, 8e-05]\n",
      "loss: 601.3067636489868, prc : 0.921346665360405, auroc : 0.8043890066502511\n",
      "epoch: 4\t| Cnt: 1\t| Loss: 0.042787299156188965\t| precision: -1\n",
      "epoch: 4\t| Cnt: 101\t| Loss: 4.330274047851563\t| precision: -1\n",
      "epoch: 4\t| Cnt: 201\t| Loss: 4.348323359489441\t| precision: -1\n",
      "epoch: 4\t| Cnt: 301\t| Loss: 4.346346969604492\t| precision: -1\n",
      "epoch: 4\t| Cnt: 401\t| Loss: 4.344483556747437\t| precision: -1\n",
      "epoch: 4\t| Cnt: 501\t| Loss: 4.3498334884643555\t| precision: -1\n",
      "epoch: 4\t| Cnt: 601\t| Loss: 4.352843823432923\t| precision: -1\n",
      "epoch: 4\t| Cnt: 701\t| Loss: 4.351753377914429\t| precision: -1\n",
      "epoch: 4\t| Cnt: 801\t| Loss: 4.359016447067261\t| precision: -1\n",
      "epoch: 4\t| Cnt: 901\t| Loss: 4.341227488517761\t| precision: -1\n",
      "epoch: 4\t| Cnt: 1001\t| Loss: 4.349269490242005\t| precision: -1\n",
      "epoch: 4\t| Cnt: 1101\t| Loss: 4.3513355588912965\t| precision: -1\n",
      "epoch: 4\t| Cnt: 1201\t| Loss: 4.358843574523926\t| precision: -1\n",
      "0\n",
      "50\n",
      "100\n",
      "** ** * Saving best fine - tuned model ** ** * \n",
      "lr:  [8e-05, 8e-05]\n",
      "loss: 603.8756847381592, prc : 0.9219428739720672, auroc : 0.8062792045496736\n",
      "epoch: 5\t| Cnt: 1\t| Loss: 0.04316981792449951\t| precision: -1\n",
      "epoch: 5\t| Cnt: 101\t| Loss: 4.339076738357544\t| precision: -1\n",
      "epoch: 5\t| Cnt: 201\t| Loss: 4.342828917503357\t| precision: -1\n",
      "epoch: 5\t| Cnt: 301\t| Loss: 4.338403739929199\t| precision: -1\n",
      "epoch: 5\t| Cnt: 401\t| Loss: 4.3349716758728025\t| precision: -1\n",
      "epoch: 5\t| Cnt: 501\t| Loss: 4.334324946403504\t| precision: -1\n",
      "epoch: 5\t| Cnt: 601\t| Loss: 4.326513843536377\t| precision: -1\n",
      "epoch: 5\t| Cnt: 701\t| Loss: 4.35918689250946\t| precision: -1\n",
      "epoch: 5\t| Cnt: 801\t| Loss: 4.339430603981018\t| precision: -1\n",
      "epoch: 5\t| Cnt: 901\t| Loss: 4.338642740249634\t| precision: -1\n",
      "epoch: 5\t| Cnt: 1001\t| Loss: 4.355057201385498\t| precision: -1\n",
      "epoch: 5\t| Cnt: 1101\t| Loss: 4.32381459236145\t| precision: -1\n",
      "epoch: 5\t| Cnt: 1201\t| Loss: 4.343559412956238\t| precision: -1\n",
      "0\n",
      "50\n",
      "100\n",
      "** ** * Saving best fine - tuned model ** ** * \n",
      "lr:  [8e-05, 8e-05]\n",
      "loss: 613.4810223579407, prc : 0.9203413106517125, auroc : 0.8067839520396572\n",
      "epoch: 6\t| Cnt: 1\t| Loss: 0.042185826301574705\t| precision: -1\n",
      "epoch: 6\t| Cnt: 101\t| Loss: 4.3308341646194455\t| precision: -1\n",
      "epoch: 6\t| Cnt: 201\t| Loss: 4.333020844459534\t| precision: -1\n",
      "epoch: 6\t| Cnt: 301\t| Loss: 4.339601159095764\t| precision: -1\n",
      "epoch: 6\t| Cnt: 401\t| Loss: 4.328499259948731\t| precision: -1\n",
      "epoch: 6\t| Cnt: 501\t| Loss: 4.344340143203735\t| precision: -1\n",
      "epoch: 6\t| Cnt: 601\t| Loss: 4.336861295700073\t| precision: -1\n",
      "epoch: 6\t| Cnt: 701\t| Loss: 4.328286824226379\t| precision: -1\n",
      "epoch: 6\t| Cnt: 801\t| Loss: 4.333792843818665\t| precision: -1\n",
      "epoch: 6\t| Cnt: 901\t| Loss: 4.333209042549133\t| precision: -1\n",
      "epoch: 6\t| Cnt: 1001\t| Loss: 4.324504480361939\t| precision: -1\n",
      "epoch: 6\t| Cnt: 1101\t| Loss: 4.335462136268616\t| precision: -1\n",
      "epoch: 6\t| Cnt: 1201\t| Loss: 4.3295205879211425\t| precision: -1\n",
      "0\n",
      "50\n",
      "100\n",
      "** ** * Saving best fine - tuned model ** ** * \n",
      "lr:  [8e-05, 8e-05]\n",
      "loss: 608.6948943138123, prc : 0.9155368741502813, auroc : 0.8076989505747095\n",
      "epoch: 7\t| Cnt: 1\t| Loss: 0.04243117332458496\t| precision: -1\n",
      "epoch: 7\t| Cnt: 101\t| Loss: 4.322579321861267\t| precision: -1\n",
      "epoch: 7\t| Cnt: 201\t| Loss: 4.325221033096313\t| precision: -1\n",
      "epoch: 7\t| Cnt: 301\t| Loss: 4.320576725006103\t| precision: -1\n",
      "epoch: 7\t| Cnt: 401\t| Loss: 4.339408192634583\t| precision: -1\n",
      "epoch: 7\t| Cnt: 501\t| Loss: 4.326526799201965\t| precision: -1\n",
      "epoch: 7\t| Cnt: 601\t| Loss: 4.331928086280823\t| precision: -1\n",
      "epoch: 7\t| Cnt: 701\t| Loss: 4.338750534057617\t| precision: -1\n",
      "epoch: 7\t| Cnt: 801\t| Loss: 4.316762375831604\t| precision: -1\n",
      "epoch: 7\t| Cnt: 901\t| Loss: 4.336556243896484\t| precision: -1\n",
      "epoch: 7\t| Cnt: 1001\t| Loss: 4.321762008666992\t| precision: -1\n",
      "epoch: 7\t| Cnt: 1101\t| Loss: 4.3440202045440675\t| precision: -1\n",
      "epoch: 7\t| Cnt: 1201\t| Loss: 4.325545239448547\t| precision: -1\n",
      "0\n",
      "50\n",
      "100\n",
      "** ** * Saving best fine - tuned model ** ** * \n",
      "lr:  [8e-05, 8e-05]\n",
      "loss: 596.7484703063965, prc : 0.9144756395942748, auroc : 0.8082694870882042\n",
      "epoch: 8\t| Cnt: 1\t| Loss: 0.04332553863525391\t| precision: -1\n",
      "epoch: 8\t| Cnt: 101\t| Loss: 4.323505172729492\t| precision: -1\n",
      "epoch: 8\t| Cnt: 201\t| Loss: 4.320400972366333\t| precision: -1\n",
      "epoch: 8\t| Cnt: 301\t| Loss: 4.320145568847656\t| precision: -1\n",
      "epoch: 8\t| Cnt: 401\t| Loss: 4.319881448745727\t| precision: -1\n",
      "epoch: 8\t| Cnt: 501\t| Loss: 4.322756309509277\t| precision: -1\n",
      "epoch: 8\t| Cnt: 601\t| Loss: 4.33314199924469\t| precision: -1\n",
      "epoch: 8\t| Cnt: 701\t| Loss: 4.319935221672058\t| precision: -1\n",
      "epoch: 8\t| Cnt: 801\t| Loss: 4.312696642875672\t| precision: -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8\t| Cnt: 901\t| Loss: 4.312656083106995\t| precision: -1\n",
      "epoch: 8\t| Cnt: 1001\t| Loss: 4.33312424659729\t| precision: -1\n",
      "epoch: 8\t| Cnt: 1101\t| Loss: 4.326858277320862\t| precision: -1\n",
      "epoch: 8\t| Cnt: 1201\t| Loss: 4.332900824546814\t| precision: -1\n",
      "0\n",
      "50\n",
      "100\n",
      "** ** * Saving best fine - tuned model ** ** * \n",
      "lr:  [8e-05, 8e-05]\n",
      "loss: 603.9590239524841, prc : 0.9127295434270675, auroc : 0.8087958371256972\n",
      "epoch: 9\t| Cnt: 1\t| Loss: 0.04247371673583984\t| precision: -1\n",
      "epoch: 9\t| Cnt: 101\t| Loss: 4.310381450653076\t| precision: -1\n",
      "epoch: 9\t| Cnt: 201\t| Loss: 4.312988433837891\t| precision: -1\n",
      "epoch: 9\t| Cnt: 301\t| Loss: 4.317403440475464\t| precision: -1\n",
      "epoch: 9\t| Cnt: 401\t| Loss: 4.309706215858459\t| precision: -1\n",
      "epoch: 9\t| Cnt: 501\t| Loss: 4.309112796783447\t| precision: -1\n",
      "epoch: 9\t| Cnt: 601\t| Loss: 4.303022751808166\t| precision: -1\n",
      "epoch: 9\t| Cnt: 701\t| Loss: 4.319072790145874\t| precision: -1\n",
      "epoch: 9\t| Cnt: 801\t| Loss: 4.330215754508973\t| precision: -1\n",
      "epoch: 9\t| Cnt: 901\t| Loss: 4.3125695657730105\t| precision: -1\n",
      "epoch: 9\t| Cnt: 1001\t| Loss: 4.317111673355103\t| precision: -1\n",
      "epoch: 9\t| Cnt: 1101\t| Loss: 4.325471801757812\t| precision: -1\n",
      "epoch: 9\t| Cnt: 1201\t| Loss: 4.320189533233642\t| precision: -1\n",
      "0\n",
      "50\n",
      "100\n",
      "0\n",
      "lr:  [8e-05, 8e-05]\n",
      "loss: 606.3328518867493, prc : 0.9171259108238403, auroc : 0.8075969531889192\n",
      "epoch: 10\t| Cnt: 1\t| Loss: 0.04245216846466064\t| precision: -1\n",
      "epoch: 10\t| Cnt: 101\t| Loss: 4.302165174484253\t| precision: -1\n",
      "epoch: 10\t| Cnt: 201\t| Loss: 4.308761477470398\t| precision: -1\n",
      "epoch: 10\t| Cnt: 301\t| Loss: 4.2916899681091305\t| precision: -1\n",
      "epoch: 10\t| Cnt: 401\t| Loss: 4.302686553001404\t| precision: -1\n",
      "epoch: 10\t| Cnt: 501\t| Loss: 4.328245635032654\t| precision: -1\n",
      "epoch: 10\t| Cnt: 601\t| Loss: 4.31761661529541\t| precision: -1\n",
      "epoch: 10\t| Cnt: 701\t| Loss: 4.305551242828369\t| precision: -1\n",
      "epoch: 10\t| Cnt: 801\t| Loss: 4.298447608947754\t| precision: -1\n",
      "epoch: 10\t| Cnt: 901\t| Loss: 4.3123263216018675\t| precision: -1\n",
      "epoch: 10\t| Cnt: 1001\t| Loss: 4.301538181304932\t| precision: -1\n",
      "epoch: 10\t| Cnt: 1101\t| Loss: 4.323375787734985\t| precision: -1\n",
      "epoch: 10\t| Cnt: 1201\t| Loss: 4.313431453704834\t| precision: -1\n",
      "0\n",
      "50\n",
      "100\n",
      "** ** * Saving best fine - tuned model ** ** * \n",
      "lr:  [8e-05, 8e-05]\n",
      "loss: 609.9708547592163, prc : 0.9085494980714495, auroc : 0.8093537657322637\n",
      "epoch: 11\t| Cnt: 1\t| Loss: 0.0432147741317749\t| precision: -1\n",
      "epoch: 11\t| Cnt: 101\t| Loss: 4.308012385368347\t| precision: -1\n",
      "epoch: 11\t| Cnt: 201\t| Loss: 4.298419795036316\t| precision: -1\n",
      "epoch: 11\t| Cnt: 301\t| Loss: 4.294211659431458\t| precision: -1\n",
      "epoch: 11\t| Cnt: 401\t| Loss: 4.301723494529724\t| precision: -1\n",
      "epoch: 11\t| Cnt: 501\t| Loss: 4.309342637062072\t| precision: -1\n",
      "epoch: 11\t| Cnt: 601\t| Loss: 4.2964336824417115\t| precision: -1\n",
      "epoch: 11\t| Cnt: 701\t| Loss: 4.30704167842865\t| precision: -1\n",
      "epoch: 11\t| Cnt: 801\t| Loss: 4.310646800994873\t| precision: -1\n",
      "epoch: 11\t| Cnt: 901\t| Loss: 4.3145379018783565\t| precision: -1\n",
      "epoch: 11\t| Cnt: 1001\t| Loss: 4.31007598400116\t| precision: -1\n",
      "epoch: 11\t| Cnt: 1101\t| Loss: 4.320294809341431\t| precision: -1\n",
      "epoch: 11\t| Cnt: 1201\t| Loss: 4.300408201217651\t| precision: -1\n",
      "0\n",
      "50\n",
      "100\n",
      "** ** * Saving best fine - tuned model ** ** * \n",
      "lr:  [8e-05, 8e-05]\n",
      "loss: 614.7653398513794, prc : 0.9167787103076941, auroc : 0.8096722806354032\n",
      "epoch: 12\t| Cnt: 1\t| Loss: 0.04329076290130615\t| precision: -1\n",
      "epoch: 12\t| Cnt: 101\t| Loss: 4.310804033279419\t| precision: -1\n",
      "epoch: 12\t| Cnt: 201\t| Loss: 4.301032691001892\t| precision: -1\n",
      "epoch: 12\t| Cnt: 301\t| Loss: 4.299381036758422\t| precision: -1\n",
      "epoch: 12\t| Cnt: 401\t| Loss: 4.2851879596710205\t| precision: -1\n",
      "epoch: 12\t| Cnt: 501\t| Loss: 4.301520457267761\t| precision: -1\n",
      "epoch: 12\t| Cnt: 601\t| Loss: 4.290938191413879\t| precision: -1\n",
      "epoch: 12\t| Cnt: 701\t| Loss: 4.300474443435669\t| precision: -1\n",
      "epoch: 12\t| Cnt: 801\t| Loss: 4.293558163642883\t| precision: -1\n",
      "epoch: 12\t| Cnt: 901\t| Loss: 4.318502073287964\t| precision: -1\n",
      "epoch: 12\t| Cnt: 1001\t| Loss: 4.303378005027771\t| precision: -1\n",
      "epoch: 12\t| Cnt: 1101\t| Loss: 4.289171061515808\t| precision: -1\n",
      "epoch: 12\t| Cnt: 1201\t| Loss: 4.303214726448059\t| precision: -1\n",
      "0\n",
      "50\n",
      "100\n",
      "0\n",
      "lr:  [8e-05, 8e-05]\n",
      "loss: 607.3154487609863, prc : 0.9105628307517146, auroc : 0.8087209385616276\n",
      "epoch: 13\t| Cnt: 1\t| Loss: 0.043401336669921874\t| precision: -1\n",
      "epoch: 13\t| Cnt: 101\t| Loss: 4.28289231300354\t| precision: -1\n",
      "epoch: 13\t| Cnt: 201\t| Loss: 4.299070920944214\t| precision: -1\n",
      "epoch: 13\t| Cnt: 301\t| Loss: 4.292517604827881\t| precision: -1\n",
      "epoch: 13\t| Cnt: 401\t| Loss: 4.286627488136292\t| precision: -1\n",
      "epoch: 13\t| Cnt: 501\t| Loss: 4.29295247554779\t| precision: -1\n",
      "epoch: 13\t| Cnt: 601\t| Loss: 4.294040274620056\t| precision: -1\n",
      "epoch: 13\t| Cnt: 701\t| Loss: 4.293606214523315\t| precision: -1\n",
      "epoch: 13\t| Cnt: 801\t| Loss: 4.2944678831100465\t| precision: -1\n",
      "epoch: 13\t| Cnt: 901\t| Loss: 4.305920901298523\t| precision: -1\n",
      "epoch: 13\t| Cnt: 1001\t| Loss: 4.291348447799683\t| precision: -1\n",
      "epoch: 13\t| Cnt: 1101\t| Loss: 4.308454151153565\t| precision: -1\n",
      "epoch: 13\t| Cnt: 1201\t| Loss: 4.314738855361939\t| precision: -1\n",
      "0\n",
      "50\n",
      "100\n",
      "1\n",
      "lr:  [8e-05, 8e-05]\n",
      "loss: 630.4773273468018, prc : 0.9116874787415583, auroc : 0.8087003052292215\n",
      "epoch: 14\t| Cnt: 1\t| Loss: 0.04092884063720703\t| precision: -1\n",
      "epoch: 14\t| Cnt: 101\t| Loss: 4.29757372379303\t| precision: -1\n",
      "epoch: 14\t| Cnt: 201\t| Loss: 4.262855410575867\t| precision: -1\n",
      "epoch: 14\t| Cnt: 301\t| Loss: 4.302801156044007\t| precision: -1\n",
      "epoch: 14\t| Cnt: 401\t| Loss: 4.283658957481384\t| precision: -1\n",
      "epoch: 14\t| Cnt: 501\t| Loss: 4.291922945976257\t| precision: -1\n",
      "epoch: 14\t| Cnt: 601\t| Loss: 4.293692193031311\t| precision: -1\n",
      "epoch: 14\t| Cnt: 701\t| Loss: 4.2923666191101075\t| precision: -1\n",
      "epoch: 14\t| Cnt: 801\t| Loss: 4.289141392707824\t| precision: -1\n",
      "epoch: 14\t| Cnt: 901\t| Loss: 4.29493851184845\t| precision: -1\n",
      "epoch: 14\t| Cnt: 1001\t| Loss: 4.301450905799865\t| precision: -1\n",
      "epoch: 14\t| Cnt: 1101\t| Loss: 4.295716667175293\t| precision: -1\n",
      "epoch: 14\t| Cnt: 1201\t| Loss: 4.287890820503235\t| precision: -1\n",
      "0\n",
      "50\n",
      "100\n",
      "LR:  [7.22e-05, 7.22e-05]\n",
      "2\n",
      "lr:  [7.22e-05, 7.22e-05]\n",
      "loss: 626.534511089325, prc : 0.9062559925276881, auroc : 0.8071009516148598\n",
      "epoch: 15\t| Cnt: 1\t| Loss: 0.041456804275512696\t| precision: -1\n",
      "epoch: 15\t| Cnt: 101\t| Loss: 4.270585412979126\t| precision: -1\n",
      "epoch: 15\t| Cnt: 201\t| Loss: 4.271583514213562\t| precision: -1\n",
      "epoch: 15\t| Cnt: 301\t| Loss: 4.282067160606385\t| precision: -1\n",
      "epoch: 15\t| Cnt: 401\t| Loss: 4.272228989601135\t| precision: -1\n",
      "epoch: 15\t| Cnt: 501\t| Loss: 4.28431987285614\t| precision: -1\n",
      "epoch: 15\t| Cnt: 601\t| Loss: 4.276211838722229\t| precision: -1\n",
      "epoch: 15\t| Cnt: 701\t| Loss: 4.279086866378784\t| precision: -1\n",
      "epoch: 15\t| Cnt: 801\t| Loss: 4.289267077445984\t| precision: -1\n",
      "epoch: 15\t| Cnt: 901\t| Loss: 4.292505340576172\t| precision: -1\n",
      "epoch: 15\t| Cnt: 1001\t| Loss: 4.298012218475342\t| precision: -1\n",
      "epoch: 15\t| Cnt: 1101\t| Loss: 4.302653031349182\t| precision: -1\n",
      "epoch: 15\t| Cnt: 1201\t| Loss: 4.289136271476746\t| precision: -1\n",
      "0\n",
      "50\n",
      "100\n",
      "LR:  [6.859e-05, 6.859e-05]\n",
      "3\n",
      "lr:  [6.859e-05, 6.859e-05]\n",
      "loss: 615.2277462482452, prc : 0.9162915898292424, auroc : 0.8076500153502314\n",
      "epoch: 16\t| Cnt: 1\t| Loss: 0.04252140522003174\t| precision: -1\n",
      "epoch: 16\t| Cnt: 101\t| Loss: 4.287770342826843\t| precision: -1\n",
      "epoch: 16\t| Cnt: 201\t| Loss: 4.277625412940979\t| precision: -1\n",
      "epoch: 16\t| Cnt: 301\t| Loss: 4.270106348991394\t| precision: -1\n",
      "epoch: 16\t| Cnt: 401\t| Loss: 4.2730144596099855\t| precision: -1\n",
      "epoch: 16\t| Cnt: 501\t| Loss: 4.263905987739563\t| precision: -1\n",
      "epoch: 16\t| Cnt: 601\t| Loss: 4.280625491142273\t| precision: -1\n",
      "epoch: 16\t| Cnt: 701\t| Loss: 4.2800487041473385\t| precision: -1\n",
      "epoch: 16\t| Cnt: 801\t| Loss: 4.286051335334778\t| precision: -1\n",
      "epoch: 16\t| Cnt: 901\t| Loss: 4.27371693611145\t| precision: -1\n",
      "epoch: 16\t| Cnt: 1001\t| Loss: 4.290166430473327\t| precision: -1\n",
      "epoch: 16\t| Cnt: 1101\t| Loss: 4.2687424421310425\t| precision: -1\n",
      "epoch: 16\t| Cnt: 1201\t| Loss: 4.291691493988037\t| precision: -1\n",
      "0\n",
      "50\n",
      "100\n",
      "LR:  [6.51605e-05, 6.51605e-05]\n",
      "4\n",
      "lr:  [6.51605e-05, 6.51605e-05]\n",
      "loss: 621.0029306411743, prc : 0.913780897454042, auroc : 0.8084424169611983\n",
      "epoch: 17\t| Cnt: 1\t| Loss: 0.041808700561523436\t| precision: -1\n",
      "epoch: 17\t| Cnt: 101\t| Loss: 4.2746050786972045\t| precision: -1\n",
      "epoch: 17\t| Cnt: 201\t| Loss: 4.259821929931641\t| precision: -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17\t| Cnt: 301\t| Loss: 4.268366560935974\t| precision: -1\n",
      "epoch: 17\t| Cnt: 401\t| Loss: 4.272680749893189\t| precision: -1\n",
      "epoch: 17\t| Cnt: 501\t| Loss: 4.271491303443908\t| precision: -1\n",
      "epoch: 17\t| Cnt: 601\t| Loss: 4.278654737472534\t| precision: -1\n",
      "epoch: 17\t| Cnt: 701\t| Loss: 4.273997535705567\t| precision: -1\n",
      "epoch: 17\t| Cnt: 801\t| Loss: 4.286304588317871\t| precision: -1\n",
      "epoch: 17\t| Cnt: 901\t| Loss: 4.275985498428344\t| precision: -1\n",
      "epoch: 17\t| Cnt: 1001\t| Loss: 4.282987775802613\t| precision: -1\n",
      "epoch: 17\t| Cnt: 1101\t| Loss: 4.268408346176147\t| precision: -1\n",
      "epoch: 17\t| Cnt: 1201\t| Loss: 4.271391277313232\t| precision: -1\n",
      "0\n",
      "50\n",
      "100\n",
      "LR:  [6.51605e-05, 6.51605e-05]\n",
      "quitting... no gains...\n",
      "best ever auauroc:  0.9167787103076941\n"
     ]
    }
   ],
   "source": [
    "auprcbest =[]\n",
    "aurocbest = []\n",
    "best_pre = -1\n",
    "patience = 0\n",
    "bestauroc = -1\n",
    "for e in range(70):\n",
    "    fullCounter = trainloop(e, BINFLAG)\n",
    "\n",
    "    prc, auroc ,loss_temp = evaluationloop(BINFLAG)\n",
    "    fullCounter = fullCounter+1\n",
    "\n",
    "    if auroc > bestauroc:\n",
    "        patience=0\n",
    "        # Save a trained model\n",
    "        print(\"** ** * Saving best fine - tuned model ** ** * \")\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "        output_model_file = os.path.join(global_params['output_dir'],  'survmodel.bin')\n",
    "        create_folder(global_params['output_dir'])\n",
    "        if global_params['save_model']:\n",
    "            torch.save(model_to_save.state_dict(), output_model_file)\n",
    "\n",
    "        best_pre = prc\n",
    "        bestauroc = auroc\n",
    "    else:\n",
    "\n",
    "\n",
    "        if patience >=2 and patience <=4:\n",
    "            scheduler.step()\n",
    "            print(\"LR: \", scheduler.get_lr())\n",
    "        elif patience>4:\n",
    "            print(\"LR: \", scheduler.get_lr())\n",
    "\n",
    "            print('quitting... no gains...')\n",
    "            break\n",
    "        print(patience)\n",
    "        patience = patience + 1\n",
    "#     scheduler.step()\n",
    "    print('lr: ' , scheduler.get_lr())\n",
    "    print('loss: {}, prc : {}, auroc : {}'.format(loss_temp, prc, auroc))\n",
    "print('best ever auauroc: ', best_pre)\n",
    "auprcbest.append(best_pre)\n",
    "aurocbest.append(bestauroc)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# surv validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "aurocbest = []\n",
    "auprcbest = []\n",
    "\n",
    "\n",
    "\n",
    "conf = BertConfig(model_config)\n",
    "\n",
    "model = BEHRTSurvModel(conf, num_labels=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "dict_keys(['bert.embeddings.word_embeddings.weight', 'bert.embeddings.segment_embeddings.weight', 'bert.embeddings.age_embeddings.weight', 'bert.embeddings.posi_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.weight', 'classifier.bias'])\n",
      "106\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fullBert = os.path.join(global_params['output_dir'],  'survmodel.bin')\n",
    "\n",
    "pretrained_dict = torch.load(fullBert, map_location='cpu')\n",
    "net_dict = model.state_dict()\n",
    "print(len(net_dict))\n",
    "# # 1. filter out unnecessary keys\n",
    "pretrained_dict2 = {k: v for k, v in pretrained_dict.items() if k in net_dict }\n",
    "# # 2. overwrite entries in the existing state dict\n",
    "print(pretrained_dict2.keys())\n",
    "\n",
    "print(len(pretrained_dict2))\n",
    "net_dict.update(pretrained_dict2) \n",
    "\n",
    "model.load_state_dict(net_dict)\n",
    "\n",
    "\n",
    "model = model.to(global_params['device'])\n",
    "optim = adam_surv(params=list(model.named_parameters()), config=optim_config)\n",
    "model.binary = BINFLAG\n",
    "\n",
    "scheduler = TriStageLRScheduler(optim,  5,5,50, 0.00001,0.000005,-1 )\n",
    "patience = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "auprcbest =[]\n",
    "aurocbest = []\n",
    "best_pre = -1\n",
    "patience = 0\n",
    "bestauroc = -1\n",
    "\n",
    "\n",
    "e,ph, t = validationloop(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import utils\n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "def get_probability(data, ph, t0, bch):\n",
    "    predictions_at_t0 = np.clip(1 - predict_survival_function(data, ph, times=[t0], bch=bch).T.squeeze(), 1e-10, 1 - 1e-10)\n",
    "    return predictions_at_t0\n",
    "    \n",
    "def predict_survival_function(test_data, ph, times, bch):\n",
    "    return np.exp(-predict_cumulative_hazard(test_data, times, ph, bch))\n",
    "\n",
    "def predict_cumulative_hazard(X, times, ph, baseline_cumulative_hazard):\n",
    "    n = X.shape[0]\n",
    "    times = np.atleast_1d(times).astype(float)\n",
    "    v = pd.Series(ph.reshape(-1))\n",
    "    col = utils._get_index(v)\n",
    "    times_ = times\n",
    "    times_to_evaluate_at = np.tile(times_, (n, 1))\n",
    "\n",
    "    c_0 = utils.interpolate_at_times(baseline_cumulative_hazard, times_to_evaluate_at).T\n",
    "\n",
    "    cumulative_hazard_ = pd.DataFrame(c_0 * v.values, columns=col, index=times_)\n",
    "    return cumulative_hazard_\n",
    "\n",
    "def get_baseline_cumulative_hazard(train):\n",
    "    time_col = 'time2event'\n",
    "    label_col = 'label'\n",
    "    formular = \"age+gen_ethnicity+imd2015_5+systolic+systolic_std+BMI+hdl+smoke+chd_history+rheumatoid_arthritis+atrial_fibrillation+ckd+migraine+lupus_erythematosus+mental_ill+hiv_aids+ED+antihtn+antipsychotic+corticosteroid\"\n",
    "\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(train, duration_col=time_col, event_col=label_col, formula=formular)\n",
    "    return cph.baseline_cumulative_hazard_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatabular = pd.read_parquet('/well/rahimi/users/sev854/project/BEHRT-Surv/data/QRISK-final.parquet/').rename(columns = {'event': 'label', 'time':'time2event' })\n",
    "datatabular = datatabular[datatabular.diabetes==1]\n",
    "train_tabular = datatabular[datatabular.patid.isin(trainpat)]\n",
    "train_tabular= train_tabular.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "get c statistics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c- statistics:  0.7887768137541917\n"
     ]
    }
   ],
   "source": [
    "t = t.view(-1).numpy()\n",
    "e = e.view(-1).numpy()\n",
    "ph = ph.view(-1).numpy()\n",
    "bch = get_baseline_cumulative_hazard(train_tabular)\n",
    "p = get_probability(data=valid, ph=ph, t0=120, bch=bch)\n",
    "\n",
    "print('c- statistics: ', concordance_index(t, -ph, e))\n",
    "\n",
    "np.savez('temp_results.npz', time=t, event=e,  pred = p.values, partial_hazard=ph)\n",
    "\n",
    "# np.savez(os.path.join(save_path, 'BEHRTSurv_scratchimplement_SurvCPHtraining__postBCE_6layers.npz'), time=t, event=e, pred=p.values, partial_hazard=ph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline haz computation and survival probability estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = np.load('temp_results.npz')\n",
    "t = dd['time']\n",
    "e = dd['event']\n",
    "ph = dd['partial_hazard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "aurocbest = []\n",
    "auprcbest = []\n",
    "\n",
    "\n",
    "\n",
    "conf = BertConfig(model_config)\n",
    "\n",
    "model = BEHRTSurvModel(conf, num_labels=1)\n",
    "\n",
    "# auc, roc, time_cost = evaluation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "dict_keys(['bert.embeddings.word_embeddings.weight', 'bert.embeddings.segment_embeddings.weight', 'bert.embeddings.age_embeddings.weight', 'bert.embeddings.posi_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.weight', 'classifier.bias'])\n",
      "106\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fullBert = os.path.join(global_params['output_dir'],  'survmodel.bin')\n",
    "\n",
    "pretrained_dict = torch.load(fullBert, map_location='cpu')\n",
    "net_dict = model.state_dict()\n",
    "print(len(net_dict))\n",
    "# # 1. filter out unnecessary keys\n",
    "pretrained_dict2 = {k: v for k, v in pretrained_dict.items() if k in net_dict }\n",
    "# # 2. overwrite entries in the existing state dict\n",
    "print(pretrained_dict2.keys())\n",
    "\n",
    "print(len(pretrained_dict2))\n",
    "net_dict.update(pretrained_dict2)\n",
    "\n",
    "model.load_state_dict(net_dict)\n",
    "\n",
    "\n",
    "model = model.to(global_params['device'])\n",
    "optim = adam_surv(params=list(model.named_parameters()), config=optim_config)\n",
    "model.binary = BINFLAG\n",
    "model.eval()\n",
    "scheduler = TriStageLRScheduler(optim,  5,5,50, 0.00001,0.000005,-1 )\n",
    "patience = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def bhcomp(df_target):\n",
    "    df_target2 = df_target.groupby('time').agg({'ph': 'sum', 'event': 'sum'}).sort_index(ascending=False)    .assign(ph=lambda x: x['ph'].cumsum()).pipe(lambda x: x['event']/x['ph']).fillna(0.).iloc[::-1].loc[lambda x: x.index <= 120] .rename('baseline_hazards')\n",
    "    df_target2 = df_target2.cumsum().rename('baseline cumulative hazards')\n",
    "    return pd.DataFrame(df_target2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "auprcbest =[]\n",
    "aurocbest = []\n",
    "best_pre = -1\n",
    "patience = 0\n",
    "bestauroc = -1\n",
    "\n",
    "\n",
    "e_train,ph_train, t_train = trainloop_bh(False, train.sample(frac=1).reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainbhdf =pd.DataFrame({'ph': ph_train.numpy().flatten(), 'event': e_train.numpy().flatten(), \"time\": t_train.numpy().flatten()})\n",
    "\n",
    "\n",
    "trainbhdf.to_parquet('ph_train.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainbhdf = pd.read_parquet('ph_train.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainbhdf_bh = bhcomp(trainbhdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import utils\n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "def get_probability(data, ph, t0, bch):\n",
    "    predictions_at_t0 = np.clip(1 - predict_survival_function(data, ph, times=[t0], bch=bch).T.squeeze(), 1e-10, 1 - 1e-10)\n",
    "    return predictions_at_t0\n",
    "    \n",
    "def predict_survival_function(test_data, ph, times, bch):\n",
    "    return np.exp(-predict_cumulative_hazard(test_data, times, ph, bch))\n",
    "\n",
    "def predict_cumulative_hazard(X, times, ph, baseline_cumulative_hazard):\n",
    "    n = X.shape[0]\n",
    "    times = np.atleast_1d(times).astype(float)\n",
    "    v = pd.Series(ph.reshape(-1))\n",
    "    col = utils._get_index(v)\n",
    "    times_ = times\n",
    "    times_to_evaluate_at = np.tile(times_, (n, 1))\n",
    "\n",
    "    c_0 = utils.interpolate_at_times(baseline_cumulative_hazard, times_to_evaluate_at).T\n",
    "\n",
    "    cumulative_hazard_ = pd.DataFrame(c_0 * v.values, columns=col, index=times_)\n",
    "    return cumulative_hazard_\n",
    "\n",
    "def get_baseline_cumulative_hazard(train):\n",
    "    time_col = 'time2event'\n",
    "    label_col = 'label'\n",
    "    formular = \"age+gen_ethnicity+imd2015_5+systolic+systolic_std+BMI+hdl+smoke+chd_history+diabetes+rheumatoid_arthritis+atrial_fibrillation+ckd+migraine+lupus_erythematosus+mental_ill+hiv_aids+ED+antihtn+antipsychotic+corticosteroid\"\n",
    "\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(train, duration_col=time_col, event_col=label_col, formula=formular)\n",
    "    return cph.baseline_cumulative_hazard_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c- statistics:  0.7887768137541917\n"
     ]
    }
   ],
   "source": [
    "\n",
    "p = get_probability(data=valid, ph=ph, t0=120, bch=trainbhdf_bh)\n",
    "\n",
    "print('c- statistics: ', concordance_index(t, -ph, e))\n",
    "\n",
    "np.savez('output_save_trisk_4analysis.npz', time=t, event=e, pred=p.values, partial_hazard=ph)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyupgrade",
   "language": "python",
   "name": "pytorch_upgrade"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
